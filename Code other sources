from flask import Flask, request, jsonify
import os
from openai import OpenAI
from datetime import datetime
from deepface import DeepFace
import cv2
import numpy as np
import dlib
from skimage import io
from facenet_pytorch import MTCNN
from PIL import Image
import exifread
from concurrent.futures import ThreadPoolExecutor
from imutils import face_utils

app = Flask(__name__)
UPLOAD_FOLDER = "uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

document_types = ["RG", "CNH", "Passaporte"]

def save_uploaded_file(file, filename):
    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
    file.save(filepath)
    return filepath

def calculate_age(birth_date):
    try:
        birth_date_obj = datetime.strptime(birth_date, "%d/%m/%Y")
        today = datetime.today()
        return today.year - birth_date_obj.year - ((today.month, today.day) < (birth_date_obj.month, birth_date_obj.day))
    except ValueError:
        return None

def detect_emotions(image_path):
    try:
        analysis = DeepFace.analyze(img_path=image_path, actions=['emotion'])
        return analysis[0]['dominant_emotion']
    except Exception as e:
        return str(e)

def estimate_age_gender(image_path):
    try:
        analysis = DeepFace.analyze(img_path=image_path, actions=['age', 'gender'])
        return analysis[0]['age'], analysis[0]['dominant_gender']
    except Exception as e:
        return None, None

def analyze_lighting_and_quality(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    brightness = np.mean(img)
    contrast = np.std(img)
    return brightness, contrast

def detect_photo_of_a_photo(image_path):
    img = cv2.imread(image_path)
    edges = cv2.Canny(img, 100, 200)
    edge_density = np.sum(edges) / (img.shape[0] * img.shape[1])
    return edge_density > 0.05

def detect_face_swaps_or_edits(image_path):
    try:
        analysis = DeepFace.analyze(img_path=image_path, actions=['emotion', 'age', 'gender'])
        if 'error' in analysis:
            return True  # Se houver erro na detecção, pode ser uma imagem manipulada
    except:
        return True  # Se falhar a análise, pode indicar manipulação
    return False

def detect_crop_or_edit(image_path):
    img = cv2.imread(image_path)
    detector = dlib.get_frontal_face_detector()
    faces = detector(img, 1)
    return len(faces) == 0

def generate_final_report(gpt_analysis, deepface_score, opencv_detected, dlib_detected, facenet_detected, exif_detected, emotion, estimated_age, estimated_gender, brightness, contrast, photo_of_photo, face_swap_detected, crop_or_edit_detected):
    client = OpenAI()
    prompt = f"""
    Com base na seguinte análise de verificação de identidade, gere um dossiê detalhado explicando a decisão final:
    {gpt_analysis}
    
    Comparação facial com DeepFace:
    - Similaridade facial detectada: {deepface_score[0]}
    - Distância de reconhecimento facial: {deepface_score[1]}
    
    Detecção facial:
    - OpenCV detectou rosto na imagem: {opencv_detected}
    - Dlib detectou rosto na imagem: {dlib_detected}
    - FaceNet detectou rosto na imagem: {facenet_detected}
    
    Análise de metadados EXIF:
    - Dados EXIF presentes: {exif_detected}
    
    Análise emocional:
    - Emoção dominante na selfie: {emotion}
    
    Estimativa de idade e gênero:
    - Idade estimada: {estimated_age}
    - Gênero estimado: {estimated_gender}
    
    Qualidade da imagem:
    - Brilho: {brightness}
    - Contraste: {contrast}
    
    Verificação de "foto sobre foto":
    - Indícios de captura de tela ou impressão detectados: {photo_of_photo}
    
    Verificação de manipulação facial:
    - Suspeita de troca de rosto ou deepfake detectada: {face_swap_detected}
    - Indícios de corte ou edição artificial: {crop_or_edit_detected}
    
    O relatório deve incluir:
    - Comparação entre os dados informados e os extraídos.
    - Explicação da idade estimada e sua correspondência com a idade esperada.
    - Verificação do gênero e sua correspondência com os dados informados.
    - Análise da autenticidade da selfie e do documento.
    - Detecção de manipulações digitais e impacto na verificação.
    - Comparação entre GPT Vision, DeepFace, OpenCV, Dlib, FaceNet e análise EXIF.
    - Justificativa clara para aprovação ou rejeição do cadastro.
    """
    
    response = client.completions.create(
        model="gpt-4",
        prompt=prompt,
        max_tokens=700
    )
    return response.choices[0].text

@app.route('/verify', methods=['POST'])
def verify():
    if 'photo' not in request.files or 'document' not in request.files or 'name' not in request.form or 'document_type' not in request.form or 'birth_date' not in request.form:
        return jsonify({'error': 'Envie uma foto, um documento, o nome, data de nascimento e o tipo de documento'}), 400

    photo = request.files['photo']
    document = request.files['document']
    provided_name = request.form['name']
    provided_birth_date = request.form['birth_date']
    document_type = request.form['document_type']

    if document_type not in document_types:
        return jsonify({'error': 'Tipo de documento inválido. Escolha entre: ' + ', '.join(document_types)}), 400

    photo_path = save_uploaded_file(photo, "photo.jpg")
    document_path = save_uploaded_file(document, f"document_{document_type}.jpg")

    with ThreadPoolExecutor() as executor:
        face_swap_detected = executor.submit(detect_face_swaps_or_edits, photo_path).result()
        crop_or_edit_detected = executor.submit(detect_crop_or_edit, photo_path).result()
    
    return jsonify({
        "face_swap_detected": face_swap_detected,
        "crop_or_edit_detected": crop_or_edit_detected
    })

if __name__ == '__main__':
    app.run(debug=True)
